{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b471551-e664-4146-8deb-ff61ac95f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        \"\"\"\n",
    "        Initialize EfficientNet model with custom classifier.\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): Number of classification categories\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=False)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        \n",
    "        # Custom multi-layer classifier\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "def load_models(model_paths, num_classes, device):\n",
    "    \"\"\"\n",
    "    Load multiple pre-trained models.\n",
    "    \n",
    "    Args:\n",
    "        model_paths (list): Paths to model weights\n",
    "        num_classes (int): Number of output classes\n",
    "        device (torch.device): Device to load models on\n",
    "    \n",
    "    Returns:\n",
    "        list: Loaded and prepared models\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    for model_path in model_paths:\n",
    "        model = EfficientNetModel(num_classes=num_classes).to(device)\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def preprocess_image(image_path, image_size=384):\n",
    "    \"\"\"\n",
    "    Preprocess input image for model inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to input image\n",
    "        image_size (int): Resize dimension\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Preprocessed image tensor\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    transforms = Compose([\n",
    "        Resize(image_size, image_size),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    transformed = transforms(image=img)\n",
    "    return transformed['image'].unsqueeze(0)\n",
    "\n",
    "def predict_with_models(models, image_tensor, device):\n",
    "    \"\"\"\n",
    "    Perform inference with multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models (list): List of trained models\n",
    "        image_tensor (torch.Tensor): Input image tensor\n",
    "        device (torch.device): Computation device\n",
    "    \n",
    "    Returns:\n",
    "        list: Predictions and confidences from each model\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    for model in models:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_class = probabilities.argmax(dim=1).item()\n",
    "            confidence = probabilities.max(dim=1).values.item()\n",
    "            predictions.append((predicted_class, confidence, probabilities.cpu().numpy()[0]))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def visualize_multi_model_predictions(image_path, predictions, class_labels):\n",
    "    \"\"\"\n",
    "    Create visualization of predictions from multiple models.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to input image\n",
    "        predictions (list): Predictions from multiple models\n",
    "        class_labels (dict): Mapping of class indices to labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Original Image\n",
    "    plt.subplot(2, 3, 1)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Original Fundus Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Individual Model Predictions\n",
    "    for i, (predicted_class, confidence, probabilities) in enumerate(predictions, start=1):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        sns.barplot(x=list(class_labels.values()), y=probabilities)\n",
    "        plt.title(f'Model {i}\\nPrediction: {class_labels[predicted_class]}\\nConfidence: {confidence:.2%}')\n",
    "        plt.xlabel('Diabetic Retinopathy Severity')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    set_seed(42)\n",
    "    model_paths = [\n",
    "        '/kaggle/input/blindness_efficentnetb0/pytorch/default/3/best_model_fold_1 (1).pth',\n",
    "        '//kaggle/input/blindness_efficentnetb0/pytorch/default/3/best_model_fold_2 (1).pth',\n",
    "        '/kaggle/input/blindness_efficentnetb0/pytorch/default/3/best_model_fold_3 (1).pth',\n",
    "        '/kaggle/input/blindness_efficentnetb0/pytorch/default/3/best_model_fold_4 (1).pth',\n",
    "        '/kaggle/input/blindness_efficentnetb0/pytorch/default/3/best_model_fold_5 (1).pth'\n",
    "    ]\n",
    "    \n",
    "    test_images = [\n",
    "        '/kaggle/input/aptos2019-blindness-detection/train_images/000c1434d8d7.png',\n",
    "        '/kaggle/input/aptos2019-blindness-detection/train_images/0024cdab0c1e.png',\n",
    "        '/kaggle/input/aptos2019-blindness-detection/train_images/0104b032c141.png'\n",
    "    ]\n",
    "    \n",
    "    class_labels = {\n",
    "        0: \"No DR\",\n",
    "        1: \"Mild\",\n",
    "        2: \"Moderate\", \n",
    "        3: \"Severe\",\n",
    "        4: \"Proliferative DR\"\n",
    "    }\n",
    "    \n",
    "    # Device and Model Setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    models = load_models(model_paths, num_classes=len(class_labels), device=device)\n",
    "    \n",
    "    # Inference and Visualization\n",
    "    for image_path in test_images:\n",
    "        try:\n",
    "            image_tensor = preprocess_image(image_path)\n",
    "            predictions = predict_with_models(models, image_tensor, device)\n",
    "            \n",
    "            print(f\"Image: {image_path}\")\n",
    "            for i, (predicted_class, confidence, _) in enumerate(predictions, start=1):\n",
    "                print(f\"Model {i} - Predicted Class: {predicted_class} ({class_labels[predicted_class]})\")\n",
    "                print(f\"Model {i} - Confidence: {confidence:.2%}\")\n",
    "            \n",
    "            visualize_multi_model_predictions(image_path, predictions, class_labels)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
